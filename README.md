# Blue_team_MechanisticInterpretability
Mechanistic Interpretability of Generative Language Models ( Fine tuning GPT-2 )
The goal of mechanistic interpretability is to take a trained model and reverse engineer the algorithms the model learned during training from its weights . we have no idea how they work nor how to write one ourselves . 
