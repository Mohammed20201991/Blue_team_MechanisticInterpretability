{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4dKWN1xPGLw"
      },
      "source": [
        "# Interactive Neuroscope\n",
        "\n",
        "*This is an interactive accompaniment to [neuroscope.io](https://neuroscope.io) and to the [studying learned language features post](https://www.alignmentforum.org/posts/Qup9gorqpd9qKAEav/200-cop-in-mi-studying-learned-features-in-language-models) in [200 Concrete Open Problems in Mechanistic Interpretability](https://neelnanda.io/concrete-open-problems)*\n",
        "\n",
        "There's a surprisingly rich ecosystem of easy ways to create interactive graphics, especially for ML systems. If you're trying to do mechanistic interpretability, the ability to do web dev and to both visualize data and interact with it seems high value! \n",
        "\n",
        "This is a demo of how you can combine HookedTransformer and [Gradio](https://gradio.app/) to create an interactive Neuroscope - a visualization of a neuron's activations on text that will dynamically update as you edit the text. I don't particularly claim that this code is any *good*, but the goal is to illustrate what quickly hacking together a custom visualisation (while knowing fuck all about web dev, like me) can look like! (And as such, I try to explain the basic web dev concepts I use)\n",
        "\n",
        "Note that you'll need to run the code yourself to get the interactive interface, so the cell at the bottom will be blank at first!\n",
        "\n",
        "To emphasise - the point of this notebook is to be a rough proof of concept that just about works, *not* to be the well executed ideal of interactively studying neurons! You are highly encouraged to write your own (and ideally, to [make a pull request](https://github.com/neelnanda-io/TransformerLens/pulls) with improvements!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgXdCnavPGL3"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZzckbMpPPGL4",
        "outputId": "d663bdb2-02e5-4b23-f7b3-d6b7785d751d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    print(ipython)\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gxxO_YSGPGL6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if IN_COLAB:\n",
        "    os.system(\"pip install git+https://github.com/neelnanda-io/TransformerLens.git\")\n",
        "    os.system(\"pip install gradio\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZYc5FQa3PGL7"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformer_lens import HookedTransformer\n",
        "from transformer_lens.utils import to_numpy\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8Q64v6mPGL7"
      },
      "source": [
        "## Extracting Model Activations\n",
        "\n",
        "We first write some code using HookedTransformer's cache to extract the neuron activations on a given layer and neuron, for a given text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-ZDgyc70PGL8",
        "outputId": "048ac506-db62-4f11-8f67-9d1e921c8362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model distilgpt2 into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "model_name = \"distilgpt2\" # NYTK/PULI-GPT-2\n",
        "model = HookedTransformer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN0Zu8NmQH2m",
        "outputId": "ec56028a-16e2-4a92-b02f-84b6b3cc65de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HookedTransformer(\n",
              "  (embed): Embed()\n",
              "  (hook_embed): HookPoint()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (hook_pos_embed): HookPoint()\n",
              "  (blocks): ModuleList(\n",
              "    (0): TransformerBlock(\n",
              "      (ln1): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (ln2): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (hook_k): HookPoint()\n",
              "        (hook_q): HookPoint()\n",
              "        (hook_v): HookPoint()\n",
              "        (hook_z): HookPoint()\n",
              "        (hook_attn_scores): HookPoint()\n",
              "        (hook_pattern): HookPoint()\n",
              "        (hook_result): HookPoint()\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (hook_pre): HookPoint()\n",
              "        (hook_post): HookPoint()\n",
              "      )\n",
              "      (hook_attn_out): HookPoint()\n",
              "      (hook_mlp_out): HookPoint()\n",
              "      (hook_resid_pre): HookPoint()\n",
              "      (hook_resid_mid): HookPoint()\n",
              "      (hook_resid_post): HookPoint()\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (ln1): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (ln2): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (hook_k): HookPoint()\n",
              "        (hook_q): HookPoint()\n",
              "        (hook_v): HookPoint()\n",
              "        (hook_z): HookPoint()\n",
              "        (hook_attn_scores): HookPoint()\n",
              "        (hook_pattern): HookPoint()\n",
              "        (hook_result): HookPoint()\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (hook_pre): HookPoint()\n",
              "        (hook_post): HookPoint()\n",
              "      )\n",
              "      (hook_attn_out): HookPoint()\n",
              "      (hook_mlp_out): HookPoint()\n",
              "      (hook_resid_pre): HookPoint()\n",
              "      (hook_resid_mid): HookPoint()\n",
              "      (hook_resid_post): HookPoint()\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (ln1): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (ln2): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (hook_k): HookPoint()\n",
              "        (hook_q): HookPoint()\n",
              "        (hook_v): HookPoint()\n",
              "        (hook_z): HookPoint()\n",
              "        (hook_attn_scores): HookPoint()\n",
              "        (hook_pattern): HookPoint()\n",
              "        (hook_result): HookPoint()\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (hook_pre): HookPoint()\n",
              "        (hook_post): HookPoint()\n",
              "      )\n",
              "      (hook_attn_out): HookPoint()\n",
              "      (hook_mlp_out): HookPoint()\n",
              "      (hook_resid_pre): HookPoint()\n",
              "      (hook_resid_mid): HookPoint()\n",
              "      (hook_resid_post): HookPoint()\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (ln1): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (ln2): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (hook_k): HookPoint()\n",
              "        (hook_q): HookPoint()\n",
              "        (hook_v): HookPoint()\n",
              "        (hook_z): HookPoint()\n",
              "        (hook_attn_scores): HookPoint()\n",
              "        (hook_pattern): HookPoint()\n",
              "        (hook_result): HookPoint()\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (hook_pre): HookPoint()\n",
              "        (hook_post): HookPoint()\n",
              "      )\n",
              "      (hook_attn_out): HookPoint()\n",
              "      (hook_mlp_out): HookPoint()\n",
              "      (hook_resid_pre): HookPoint()\n",
              "      (hook_resid_mid): HookPoint()\n",
              "      (hook_resid_post): HookPoint()\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (ln1): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (ln2): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (hook_k): HookPoint()\n",
              "        (hook_q): HookPoint()\n",
              "        (hook_v): HookPoint()\n",
              "        (hook_z): HookPoint()\n",
              "        (hook_attn_scores): HookPoint()\n",
              "        (hook_pattern): HookPoint()\n",
              "        (hook_result): HookPoint()\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (hook_pre): HookPoint()\n",
              "        (hook_post): HookPoint()\n",
              "      )\n",
              "      (hook_attn_out): HookPoint()\n",
              "      (hook_mlp_out): HookPoint()\n",
              "      (hook_resid_pre): HookPoint()\n",
              "      (hook_resid_mid): HookPoint()\n",
              "      (hook_resid_post): HookPoint()\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (ln1): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (ln2): LayerNormPre(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (hook_k): HookPoint()\n",
              "        (hook_q): HookPoint()\n",
              "        (hook_v): HookPoint()\n",
              "        (hook_z): HookPoint()\n",
              "        (hook_attn_scores): HookPoint()\n",
              "        (hook_pattern): HookPoint()\n",
              "        (hook_result): HookPoint()\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (hook_pre): HookPoint()\n",
              "        (hook_post): HookPoint()\n",
              "      )\n",
              "      (hook_attn_out): HookPoint()\n",
              "      (hook_mlp_out): HookPoint()\n",
              "      (hook_resid_pre): HookPoint()\n",
              "      (hook_resid_mid): HookPoint()\n",
              "      (hook_resid_post): HookPoint()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNormPre(\n",
              "    (hook_scale): HookPoint()\n",
              "    (hook_normalized): HookPoint()\n",
              "  )\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # to be removed later \n",
        "# from transformers import GPT2Tokenizer, GPT2Model\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "# model2 = GPT2Model.from_pretrained('gpt2')\n",
        "# text = \"Replace me by any text you'd like.\"\n",
        "# encoded_input = tokenizer(text, return_tensors='pt')\n",
        "# output = model2(**encoded_input)"
      ],
      "metadata": {
        "id": "TCRUIk5Kmj-1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.generation.utils import MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING\n",
        "MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING #.__dict__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytZka3UVm7NG",
        "outputId": "6ad7b699-3ef2-480e-c882-b046d6213e86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_LazyAutoMapping()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ei97c4taPGL9"
      },
      "outputs": [],
      "source": [
        "def get_neuron_acts(text, layer, neuron_index):\n",
        "    # Hacky way to get out state from a single hook - we have a single element list and edit that list within the hook.\n",
        "    cache = {}\n",
        "\n",
        "    def caching_hook(act, hook):\n",
        "        cache[\"activation\"] = act[0, :, neuron_index]\n",
        "\n",
        "    model.run_with_hooks(\n",
        "        text, fwd_hooks=[(f\"blocks.{layer}.mlp.hook_post\", caching_hook)]\n",
        "    )\n",
        "    return to_numpy(cache[\"activation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Zw0gjdPGL-"
      },
      "source": [
        "We can run this function and verify that it gives vaguely sensible outputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# default_layer = 0\n",
        "# default_neuron_index = 3071\n",
        "# default_text = \"Bill Moyers criticized the corporate media for parroting the\"\n",
        "# # default_text = \"Bill Moyers kritizálta a vállalati médiát mert utánozták a\"\n",
        "# print(model.to_str_tokens(default_text))\n",
        "# print(get_neuron_acts(default_text, default_layer, default_neuron_index))"
      ],
      "metadata": {
        "id": "98Dzpd_RtSDu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_layer = 5\n",
        "default_neuron_index = 220\n",
        "default_text = 'the Brothers (and Salafis) argue that while it is not mandatory, it is nevertheless mukarama (preferable, pleasing in the eyes of God).[57] One hadith from the Sunan Abu Dawood collection states: \"A woman used to perform circumcision in Medina\"'\n",
        "# default_text = \"Bill Moyers kritizálta a vállalati médiát mert utánozták a\"\n",
        "print(model.to_str_tokens(default_text))\n",
        "print(get_neuron_acts(default_text, default_layer, default_neuron_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh7eyJoUMfQG",
        "outputId": "35306b4d-99ba-4006-b086-e9e2f6ad2c1b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|endoftext|>', 'the', ' Brothers', ' (', 'and', ' Sal', 'af', 'is', ')', ' argue', ' that', ' while', ' it', ' is', ' not', ' mandatory', ',', ' it', ' is', ' nevertheless', ' m', 'uk', 'ar', 'ama', ' (', 'pre', 'fer', 'able', ',', ' pleasing', ' in', ' the', ' eyes', ' of', ' God', ').[', '57', ']', ' One', ' had', 'ith', ' from', ' the', ' Sun', 'an', ' Abu', ' Daw', 'ood', ' collection', ' states', ':', ' \"', 'A', ' woman', ' used', ' to', ' perform', ' circumcision', ' in', ' Medina', '\"']\n",
            "[-0.09019658 -0.16825671 -0.16022548 -0.10385371 -0.16405521 -0.12235729\n",
            "  0.12736283 -0.16036858 -0.15163518 -0.15545735 -0.16369638 -0.16364644\n",
            " -0.16536835 -0.15426308 -0.15184145 -0.01847607 -0.07175732 -0.13938677\n",
            " -0.12283999 -0.14176096 -0.16275087 -0.12137292 -0.15182668 -0.16854402\n",
            " -0.15053138 -0.16540338 -0.08222538 -0.13916709 -0.1110108  -0.0836805\n",
            " -0.06269553 -0.04969161 -0.04285033 -0.06914173 -0.04093773 -0.07153136\n",
            " -0.07366642 -0.11953531 -0.13063058 -0.14887872 -0.14031702 -0.100984\n",
            " -0.08735689 -0.1257798  -0.1307348  -0.15216658 -0.09925007 -0.11645029\n",
            " -0.16961572 -0.11716732 -0.09728693 -0.12917487 -0.15304792 -0.12109021\n",
            " -0.06023592 -0.12418018 -0.05660514 -0.09330777 -0.15382323 -0.12229802\n",
            " -0.13538375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://neuroscope.io/gpt2-small/5/220.html\n",
        "\n",
        "Model: disttiled-gpt-2:\n",
        "\n",
        " 6  Layers, ? Neurons per Layer\n",
        "Dataset: Open Web Text\n",
        "Neuron 220 in Layer 5\n",
        "Max Range: 4.8084. Min Range: -4.8084\n",
        "Max Act: 4.7290. Min Act: -0.1700\n",
        "Data Index: 4108216 (Open Web Text)\n",
        "Max Activating Token Index: 225"
      ],
      "metadata": {
        "id": "Ktb89ZZEOKTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trancuted \n",
        " in prison in Kiribati as of September of that year.[261] No information was located on whether any children resided in prison with the women. \n",
        " \n",
        "Back to Top \n",
        " \n",
        "Kuwait \n",
        " \n",
        "Article 34 of Law No. 26 of 1962 states that a newborn in Kuwait can remain with his/"
      ],
      "metadata": {
        "id": "17-wEH62NZkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Text\n",
        "Full Text #1\n",
        "\n",
        "<|endoftext|> indicated that Kenya has an average of three hundred children aged zero to fifty-nine months living with their mothers in the thirty-five women��s prisons around the country.[257] A 2013 US State Department report indicated that 117 of the 4,314 prisoners nationwide in 2012 were women.[258] \n",
        " \n",
        "Back to Top \n",
        " \n",
        "Kiribati \n",
        " \n",
        "In Kiribati, the Prisons Ordinance provides that an infant child of a female prisoner may be received into prison with its mother and ��may be supplied with clothing and necessaries at the public expense.��[259] When the child has been weaned, the officer in charge must send the child to relatives or friends, provided there are such relatives or friends capable and willing to support the child.[260] According to a 2013 US Department of State report, there were four female detainees in prison in Kiribati as of September of that year.[261] No information was located on whether any children resided in prison with the women. \n",
        " \n",
        "Back to Top \n",
        " \n",
        "Kuwait \n",
        " \n",
        "Article 34 of Law No. 26 of 1962 states that a newborn in Kuwait can remain with his/her imprisoned mother until the child reaches the age of two. If the mother is not willing to have the child stay with her or when the child has reached two years of age, the child must live with his/her father or any relative selected by the mother. If the child does not have a father or any other relatives, the prison authorities place the child in an outside orphanage. The imprisoned mother will be notified of the location of the orphanage so that she can visit the child in accordance with regulations.[262] No information was located on the number of children residing in prison with their mothers. \n",
        " \n",
        "Back to Top \n",
        " \n",
        "Libya \n",
        " \n",
        "Pursuant to the Law on Reform and Rehabilitation Institutions, a pregnant woman inmate shall be treated during the pregnancy and until forty days after delivery in accordance with what the physician in charge decides.[263] The same treatment may be accorded to the breast-feeding inmate if so decided by the physician. The woman inmate is allowed to keep her child with her until he is two years old.[264] Information on the number of children living with their mothers in prison could not be located. \n",
        " \n",
        "Back to Top \n",
        " \n",
        "Luxembourg \n",
        " \n",
        "Children who are too young be separated from their mother are allowed to stay with their mother in prison.[265] \n",
        " \n",
        "Back to Top \n",
        " \n",
        "Malawi \n",
        " \n",
        "Malawian law provides that a breastfeeding child of a female prisoner may be permitted to live with the mother until the child has been weaned. During the child��s stay with the mother, the child may be provided with ��clothing and necessaries at the public expense.��[266] Once the child has been weaned, the Prison Service is required to place the child with a relative or family friend able and willing to support the child and, in the absence of such a person, with a government-approved child care provider.[267] \n",
        " \n",
        "A 2013 US Department of State report indicated that there were a total of 12,505 inmates in the country��s prisons, 107 of whom were women.[268] No statistical information regarding the number of children currently living in prison with their mothers was located. \n",
        " \n",
        "Back to Top \n",
        " \n",
        "Malaysia \n",
        " \n",
        "Under the Malaysian Prison Act 1995, regulations may be issued for various matters, including ��the treatment and wellbeing of a child born to a prisoner while in custody and a child of a female prisoner admitted with his mother.��[269] The Prisons Regulations 2000 provide that a child under the age of three years may be admitted with his or her mother.[270] Such a child ��must be provided with basic necessities for the child��s maintenance and care by the Director General.��[271] Furthermore, the Medical Officer must, where possible, ��see every child accompanying [a] female prisoner as often as necessary.��[272] The regulations also specify the daily diet for each child.[273] \n",
        " \n",
        "When a child reaches the age of three years, a Medical Officer must report on whether the child should be retained in the prison for a longer period.[274] However, except by special authority of the Director General, no child may be kept in prison after he or she reaches the age of four years.[275] Special instructions from the Director General must be sought if a child reaches the age of three or four years and there are no known relations willing or in a position to receive the child.[276] No information on the number of children residing in prisons with their mothers could be located. \n",
        " \n",
        "Back to Top \n",
        " \n",
        "Mali \n",
        " \n",
        "Malian law appears to allow mothers to keep their young children with them in prison. According to Association Asmae Soeur Emmanuelle, a nongovernmental organization that focuses on child poverty, sixty-nine babies or young children lived with their"
      ],
      "metadata": {
        "id": "-z5HLtBhNNBP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbGY-mscPGMA"
      },
      "source": [
        "## Visualizing Model Activations\n",
        "\n",
        "We now write some code to visualize the neuron activations on some text - we're going to hack something together which just does some string processing to make an HTML string, with each token element colored according to the intensity neuron activation. We normalize the neuron activations so they all lie in [0, 1]. You can do much better, but this is a useful proof of concept of what \"just hack stuff together\" can look like!\n",
        "\n",
        "I'll be keeping neuron 562 in layer 9 as a running example, as it seems to activate strongly on powers of 10.\n",
        "\n",
        "Note that this visualization is very sensitive to `max_val` and `min_val`! You can tune those to whatever seems reasonable for the distribution of neuron activations you care about - I generally default to `min_val=0` and `max_val` as the max activation across the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CNpxK5DmPGMA"
      },
      "outputs": [],
      "source": [
        "# This is some CSS (tells us what style )to give each token a thin gray border, to make it easy to see token separation\n",
        "style_string = \"\"\"<style> \n",
        "    span.token {\n",
        "        border: 1px solid rgb(123, 123, 123)\n",
        "        } \n",
        "    </style>\"\"\"\n",
        "\n",
        "\n",
        "def calculate_color(val, max_val, min_val):\n",
        "    # Hacky code that takes in a value val in range [min_val, max_val], normalizes it to [0, 1] and returns a color which interpolates between slightly off-white and red (0 = white, 1 = red)\n",
        "    # We return a string of the form \"rgb(240, 240, 240)\" which is a color CSS knows\n",
        "    normalized_val = (val - min_val) / max_val\n",
        "    return f\"rgb(240, {240*(1-normalized_val)}, {240*(1-normalized_val)})\"\n",
        "\n",
        "\n",
        "def basic_neuron_vis(text, layer, neuron_index, max_val=None, min_val=None):\n",
        "    \"\"\"\n",
        "    text: The text to visualize\n",
        "    layer: The layer index\n",
        "    neuron_index: The neuron index\n",
        "    max_val: The top end of our activation range, defaults to the maximum activation\n",
        "    min_val: The top end of our activation range, defaults to the minimum activation\n",
        "\n",
        "    Returns a string of HTML that displays the text with each token colored according to its activation\n",
        "\n",
        "    Note: It's useful to be able to input a fixed max_val and min_val, because otherwise the colors will change as you edit the text, which is annoying.\n",
        "    \"\"\"\n",
        "    if layer is None:\n",
        "        return \"Please select a Layer\"\n",
        "    if neuron_index is None:\n",
        "        return \"Please select a Neuron\"\n",
        "    acts = get_neuron_acts(text, layer, neuron_index)\n",
        "    print('acts ', acts , '\\n')\n",
        "    act_max = acts.max()\n",
        "    act_min = acts.min()\n",
        "    print('act_max :', act_max,'\\n act_min : ', act_min )\n",
        "    # Defaults to the max and min of the activations\n",
        "    if max_val is None:\n",
        "        max_val = act_max\n",
        "    if min_val is None:\n",
        "        min_val = act_min\n",
        "    # We want to make a list of HTML strings to concatenate into our final HTML string\n",
        "    # We first add the style to make each token element have a nice border\n",
        "    htmls = [style_string]\n",
        "    # We then add some text to tell us what layer and neuron we're looking at \n",
        "    # - we're just dealing with strings and can use f-strings as normal\n",
        "    # h4 means \"small heading\"\n",
        "    htmls.append(f\"<h4>Layer: <b>{layer}</b>. Neuron Index: <b>{neuron_index}</b></h4>\")\n",
        "    # We then add a line telling us the limits of our range\n",
        "    htmls.append(\n",
        "        f\"<h4>Max Range: <b>{max_val:.4f}</b>. Min Range: <b>{min_val:.4f}</b></h4>\"\n",
        "    )\n",
        "    # If we added a custom range, print a line telling us the range of our activations too.\n",
        "    if act_max != max_val or act_min != min_val:\n",
        "        htmls.append(\n",
        "            f\"<h4>Custom Range Set. Max Act: <b>{act_max:.4f}</b>. Min Act: <b>{act_min:.4f}</b></h4>\"\n",
        "        )\n",
        "    # Convert the text to a list of tokens\n",
        "    str_tokens = model.to_str_tokens(text)\n",
        "    print('str_tokens', str_tokens)\n",
        "    for tok, act in zip(str_tokens, acts):\n",
        "        # A span is an HTML element that lets us style a part of a string (and remains on the same line by default)\n",
        "        # We set the background color of the span to be the color we calculated from the activation\n",
        "        # We set the contents of the span to be the token\n",
        "        htmls.append(\n",
        "            f\"<span class='token' style='background-color:{calculate_color(act, max_val, min_val)}' >{tok}</span>\"\n",
        "        )\n",
        "\n",
        "    return \"\".join(htmls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4j2Q39r2PGMB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "76eebfe0-626a-478d-f892-da49f4700ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acts  [-0.09019658 -0.16825671 -0.16022548 -0.10385371 -0.16405521 -0.12235729\n",
            "  0.12736283 -0.16036858 -0.15163518 -0.15545735 -0.16369638 -0.16364644\n",
            " -0.16536835 -0.15426308 -0.15184145 -0.01847607 -0.07175732 -0.13938677\n",
            " -0.12283999 -0.14176096 -0.16275087 -0.12137292 -0.15182668 -0.16854402\n",
            " -0.15053138 -0.16540338 -0.08222538 -0.13916709 -0.1110108  -0.0836805\n",
            " -0.06269553 -0.04969161 -0.04285033 -0.06914173 -0.04093773 -0.07153136\n",
            " -0.07366642 -0.11953531 -0.13063058 -0.14887872 -0.14031702 -0.100984\n",
            " -0.08735689 -0.1257798  -0.1307348  -0.15216658 -0.09925007 -0.11645029\n",
            " -0.16961572 -0.11716732 -0.09728693 -0.12917487 -0.15304792 -0.12109021\n",
            " -0.06023592 -0.12418018 -0.05660514 -0.09330777 -0.15382323 -0.12229802\n",
            " -0.13538375] \n",
            "\n",
            "act_max : 0.12736283 \n",
            " act_min :  -0.16961572\n",
            "str_tokens ['<|endoftext|>', 'the', ' Brothers', ' (', 'and', ' Sal', 'af', 'is', ')', ' argue', ' that', ' while', ' it', ' is', ' not', ' mandatory', ',', ' it', ' is', ' nevertheless', ' m', 'uk', 'ar', 'ama', ' (', 'pre', 'fer', 'able', ',', ' pleasing', ' in', ' the', ' eyes', ' of', ' God', ').[', '57', ']', ' One', ' had', 'ith', ' from', ' the', ' Sun', 'an', ' Abu', ' Daw', 'ood', ' collection', ' states', ':', ' \"', 'A', ' woman', ' used', ' to', ' perform', ' circumcision', ' in', ' Medina', '\"']\n",
            "Displayed HTML\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style> \n",
              "    span.token {\n",
              "        border: 1px solid rgb(123, 123, 123)\n",
              "        } \n",
              "    </style><h4>Layer: <b>5</b>. Neuron Index: <b>220</b></h4><h4>Max Range: <b>2.0000</b>. Min Range: <b>-2.0000</b></h4><h4>Custom Range Set. Max Act: <b>0.1274</b>. Min Act: <b>-0.1696</b></h4><span class='token' style='background-color:rgb(240, 10.823589563369751, 10.823589563369751)' ><|endoftext|></span><span class='token' style='background-color:rgb(240, 20.190805792808533, 20.190805792808533)' >the</span><span class='token' style='background-color:rgb(240, 19.227057695388794, 19.227057695388794)' > Brothers</span><span class='token' style='background-color:rgb(240, 12.462445199489594, 12.462445199489594)' > (</span><span class='token' style='background-color:rgb(240, 19.686625599861145, 19.686625599861145)' >and</span><span class='token' style='background-color:rgb(240, 14.682874381542206, 14.682874381542206)' > Sal</span><span class='token' style='background-color:rgb(240, -15.283539891242981, -15.283539891242981)' >af</span><span class='token' style='background-color:rgb(240, 19.244229197502136, 19.244229197502136)' >is</span><span class='token' style='background-color:rgb(240, 18.196222186088562, 18.196222186088562)' >)</span><span class='token' style='background-color:rgb(240, 18.654881715774536, 18.654881715774536)' > argue</span><span class='token' style='background-color:rgb(240, 19.64356541633606, 19.64356541633606)' > that</span><span class='token' style='background-color:rgb(240, 19.63757336139679, 19.63757336139679)' > while</span><span class='token' style='background-color:rgb(240, 19.844201803207397, 19.844201803207397)' > it</span><span class='token' style='background-color:rgb(240, 18.511569499969482, 18.511569499969482)' > is</span><span class='token' style='background-color:rgb(240, 18.22097361087799, 18.22097361087799)' > not</span><span class='token' style='background-color:rgb(240, 2.2171278297901154, 2.2171278297901154)' > mandatory</span><span class='token' style='background-color:rgb(240, 8.610877990722656, 8.610877990722656)' >,</span><span class='token' style='background-color:rgb(240, 16.726412773132324, 16.726412773132324)' > it</span><span class='token' style='background-color:rgb(240, 14.740798473358154, 14.740798473358154)' > is</span><span class='token' style='background-color:rgb(240, 17.01131522655487, 17.01131522655487)' > nevertheless</span><span class='token' style='background-color:rgb(240, 19.530104398727417, 19.530104398727417)' > m</span><span class='token' style='background-color:rgb(240, 14.564749896526337, 14.564749896526337)' >uk</span><span class='token' style='background-color:rgb(240, 18.21920156478882, 18.21920156478882)' >ar</span><span class='token' style='background-color:rgb(240, 20.225282907485962, 20.225282907485962)' >ama</span><span class='token' style='background-color:rgb(240, 18.06376576423645, 18.06376576423645)' > (</span><span class='token' style='background-color:rgb(240, 19.848405718803406, 19.848405718803406)' >pre</span><span class='token' style='background-color:rgb(240, 9.867045879364014, 9.867045879364014)' >fer</span><span class='token' style='background-color:rgb(240, 16.700050234794617, 16.700050234794617)' >able</span><span class='token' style='background-color:rgb(240, 13.32129567861557, 13.32129567861557)' >,</span><span class='token' style='background-color:rgb(240, 10.041659474372864, 10.041659474372864)' > pleasing</span><span class='token' style='background-color:rgb(240, 7.523463070392609, 7.523463070392609)' > in</span><span class='token' style='background-color:rgb(240, 5.9629932045936584, 5.9629932045936584)' > the</span><span class='token' style='background-color:rgb(240, 5.142040103673935, 5.142040103673935)' > eyes</span><span class='token' style='background-color:rgb(240, 8.29700767993927, 8.29700767993927)' > of</span><span class='token' style='background-color:rgb(240, 4.912527501583099, 4.912527501583099)' > God</span><span class='token' style='background-color:rgb(240, 8.583763539791107, 8.583763539791107)' >).[</span><span class='token' style='background-color:rgb(240, 8.83996993303299, 8.83996993303299)' >57</span><span class='token' style='background-color:rgb(240, 14.344237446784973, 14.344237446784973)' >]</span><span class='token' style='background-color:rgb(240, 15.67566990852356, 15.67566990852356)' > One</span><span class='token' style='background-color:rgb(240, 17.86544680595398, 17.86544680595398)' > had</span><span class='token' style='background-color:rgb(240, 16.838042736053467, 16.838042736053467)' >ith</span><span class='token' style='background-color:rgb(240, 12.118079960346222, 12.118079960346222)' > from</span><span class='token' style='background-color:rgb(240, 10.48282653093338, 10.48282653093338)' > the</span><span class='token' style='background-color:rgb(240, 15.093575119972229, 15.093575119972229)' > Sun</span><span class='token' style='background-color:rgb(240, 15.688176155090332, 15.688176155090332)' >an</span><span class='token' style='background-color:rgb(240, 18.259989023208618, 18.259989023208618)' > Abu</span><span class='token' style='background-color:rgb(240, 11.910008490085602, 11.910008490085602)' > Daw</span><span class='token' style='background-color:rgb(240, 13.974035382270813, 13.974035382270813)' >ood</span><span class='token' style='background-color:rgb(240, 20.353885889053345, 20.353885889053345)' > collection</span><span class='token' style='background-color:rgb(240, 14.060077965259552, 14.060077965259552)' > states</span><span class='token' style='background-color:rgb(240, 11.67443186044693, 11.67443186044693)' >:</span><span class='token' style='background-color:rgb(240, 15.500984787940979, 15.500984787940979)' > \"</span><span class='token' style='background-color:rgb(240, 18.365750312805176, 18.365750312805176)' >A</span><span class='token' style='background-color:rgb(240, 14.530825316905975, 14.530825316905975)' > woman</span><span class='token' style='background-color:rgb(240, 7.22831055521965, 7.22831055521965)' > used</span><span class='token' style='background-color:rgb(240, 14.901621043682098, 14.901621043682098)' > to</span><span class='token' style='background-color:rgb(240, 6.792616546154022, 6.792616546154022)' > perform</span><span class='token' style='background-color:rgb(240, 11.19693249464035, 11.19693249464035)' > circumcision</span><span class='token' style='background-color:rgb(240, 18.458787202835083, 18.458787202835083)' > in</span><span class='token' style='background-color:rgb(240, 14.675762057304382, 14.675762057304382)' > Medina</span><span class='token' style='background-color:rgb(240, 16.246050596237183, 16.246050596237183)' >\"</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML String - it's just raw HTML code!\n",
            "<style> \n",
            "    span.token {\n",
            "        border: 1px solid rgb(123, 123, 123)\n",
            "        } \n",
            "    </style><h4>Layer: <b>5</b>. Neuron Index: <b>220</b></h4><h4>Max Range: <b>2.0000</b>. Min Range: <b>-2.0000</b></h4><h4>Custom Range Set. Max Act: <b>0.1274</b>. Min Act: <b>-0.1696</b></h4><span class='token' style='background-color:rgb(240, 10.823589563369751, 10.823589563369751)' ><|endoftext|></span><span class='token' style='background-color:rgb(240, 20.190805792808533, 20.190805792808533)' >the</span><span class='token' style='background-color:rgb(240, 19.227057695388794, 19.227057695388794)' > Brothers</span><span class='token' style='background-color:rgb(240, 12.462445199489594, 12.462445199489594)' > (</span><span class='token' style='background-color:rgb(240, 19.686625599861145, 19.686625599861145)' >and</span><span class='token' style='background-color:rgb(240, 14.682874381542206, 14.682874381542206)' > Sal</span><span class='token' style='background-color:rgb(240, -15.283539891242981, -15.283539891242981)' >af</span><span class='token' style='background-color:rgb(240, 19.244229197502136, 19.244229197502136)' >is</span><span class='token' style='background-color:rgb(240, 18.196222186088562, 18.196222186088562)' >)</span><span class='token' style='background-color:rgb(240, 18.654881715774536, 18.654881715774536)' > argue</span><span class='token' style='background-color:rgb(240, 19.64356541633606, 19.64356541633606)' > that</span><span class='token' style='background-color:rgb(240, 19.63757336139679, 19.63757336139679)' > while</span><span class='token' style='background-color:rgb(240, 19.844201803207397, 19.844201803207397)' > it</span><span class='token' style='background-color:rgb(240, 18.511569499969482, 18.511569499969482)' > is</span><span class='token' style='background-color:rgb(240, 18.22097361087799, 18.22097361087799)' > not</span><span class='token' style='background-color:rgb(240, 2.2171278297901154, 2.2171278297901154)' > mandatory</span><span class='token' style='background-color:rgb(240, 8.610877990722656, 8.610877990722656)' >,</span><span class='token' style='background-color:rgb(240, 16.726412773132324, 16.726412773132324)' > it</span><span class='token' style='background-color:rgb(240, 14.740798473358154, 14.740798473358154)' > is</span><span class='token' style='background-color:rgb(240, 17.01131522655487, 17.01131522655487)' > nevertheless</span><span class='token' style='background-color:rgb(240, 19.530104398727417, 19.530104398727417)' > m</span><span class='token' style='background-color:rgb(240, 14.564749896526337, 14.564749896526337)' >uk</span><span class='token' style='background-color:rgb(240, 18.21920156478882, 18.21920156478882)' >ar</span><span class='token' style='background-color:rgb(240, 20.225282907485962, 20.225282907485962)' >ama</span><span class='token' style='background-color:rgb(240, 18.06376576423645, 18.06376576423645)' > (</span><span class='token' style='background-color:rgb(240, 19.848405718803406, 19.848405718803406)' >pre</span><span class='token' style='background-color:rgb(240, 9.867045879364014, 9.867045879364014)' >fer</span><span class='token' style='background-color:rgb(240, 16.700050234794617, 16.700050234794617)' >able</span><span class='token' style='background-color:rgb(240, 13.32129567861557, 13.32129567861557)' >,</span><span class='token' style='background-color:rgb(240, 10.041659474372864, 10.041659474372864)' > pleasing</span><span class='token' style='background-color:rgb(240, 7.523463070392609, 7.523463070392609)' > in</span><span class='token' style='background-color:rgb(240, 5.9629932045936584, 5.9629932045936584)' > the</span><span class='token' style='background-color:rgb(240, 5.142040103673935, 5.142040103673935)' > eyes</span><span class='token' style='background-color:rgb(240, 8.29700767993927, 8.29700767993927)' > of</span><span class='token' style='background-color:rgb(240, 4.912527501583099, 4.912527501583099)' > God</span><span class='token' style='background-color:rgb(240, 8.583763539791107, 8.583763539791107)' >).[</span><span class='token' style='background-color:rgb(240, 8.83996993303299, 8.83996993303299)' >57</span><span class='token' style='background-color:rgb(240, 14.344237446784973, 14.344237446784973)' >]</span><span class='token' style='background-color:rgb(240, 15.67566990852356, 15.67566990852356)' > One</span><span class='token' style='background-color:rgb(240, 17.86544680595398, 17.86544680595398)' > had</span><span class='token' style='background-color:rgb(240, 16.838042736053467, 16.838042736053467)' >ith</span><span class='token' style='background-color:rgb(240, 12.118079960346222, 12.118079960346222)' > from</span><span class='token' style='background-color:rgb(240, 10.48282653093338, 10.48282653093338)' > the</span><span class='token' style='background-color:rgb(240, 15.093575119972229, 15.093575119972229)' > Sun</span><span class='token' style='background-color:rgb(240, 15.688176155090332, 15.688176155090332)' >an</span><span class='token' style='background-color:rgb(240, 18.259989023208618, 18.259989023208618)' > Abu</span><span class='token' style='background-color:rgb(240, 11.910008490085602, 11.910008490085602)' > Daw</span><span class='token' style='background-color:rgb(240, 13.974035382270813, 13.974035382270813)' >ood</span><span class='token' style='background-color:rgb(240, 20.353885889053345, 20.353885889053345)' > collection</span><span class='token' style='background-color:rgb(240, 14.060077965259552, 14.060077965259552)' > states</span><span class='token' style='background-color:rgb(240, 11.67443186044693, 11.67443186044693)' >:</span><span class='token' style='background-color:rgb(240, 15.500984787940979, 15.500984787940979)' > \"</span><span class='token' style='background-color:rgb(240, 18.365750312805176, 18.365750312805176)' >A</span><span class='token' style='background-color:rgb(240, 14.530825316905975, 14.530825316905975)' > woman</span><span class='token' style='background-color:rgb(240, 7.22831055521965, 7.22831055521965)' > used</span><span class='token' style='background-color:rgb(240, 14.901621043682098, 14.901621043682098)' > to</span><span class='token' style='background-color:rgb(240, 6.792616546154022, 6.792616546154022)' > perform</span><span class='token' style='background-color:rgb(240, 11.19693249464035, 11.19693249464035)' > circumcision</span><span class='token' style='background-color:rgb(240, 18.458787202835083, 18.458787202835083)' > in</span><span class='token' style='background-color:rgb(240, 14.675762057304382, 14.675762057304382)' > Medina</span><span class='token' style='background-color:rgb(240, 16.246050596237183, 16.246050596237183)' >\"</span>\n"
          ]
        }
      ],
      "source": [
        "# The function outputs a string of HTML\n",
        "default_max_val =  2.0\n",
        "default_min_val = -2.0\n",
        "default_html_string = basic_neuron_vis(\n",
        "    default_text,\n",
        "    default_layer,\n",
        "    default_neuron_index,\n",
        "    max_val=default_max_val,\n",
        "    min_val=default_min_val,\n",
        ")\n",
        "\n",
        "# IPython lets us display HTML\n",
        "print(\"Displayed HTML\")\n",
        "display(HTML(default_html_string))\n",
        "\n",
        "# We can also print the string directly\n",
        "print(\"HTML String - it's just raw HTML code!\")\n",
        "print(default_html_string)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print()"
      ],
      "metadata": {
        "id": "39LHLldx56ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49fe6c93-326e-4afb-ac3e-285292e07fdf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW161buKPGMC"
      },
      "source": [
        "## Create Interactive UI\n",
        "\n",
        "We now put all these together to create an interactive visualization in Gradio! \n",
        "\n",
        "The internal format is that there's a bunch of elements - Textboxes, Numbers, etc which the user can interact with and which return strings and numbers. And we can also define output elements that just display things - in this case, one which takes in an arbitrary HTML string. We call `input.change(update_function, inputs, output)` - this says \"if that input element changes, run the update function on the value of each of the elements in `inputs` and set the value of `output` to the output of the function\". As a bonus, this gives us live interactivity!\n",
        "\n",
        "This is also more complex than a typical Gradio intro example - I wanted to use custom HTML to display the nice colours, which made things much messier! Normally you could just make `out` into another Textbox and pass it a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LV5dM9mGPGMC"
      },
      "outputs": [],
      "source": [
        "# The `with gr.Blocks() as demo:` syntax just creates a variable called demo containing all these components\n",
        "with gr.Blocks() as demo:\n",
        "    gr.HTML(value=f\"Hacky Interactive Neuroscope for {model_name}\")\n",
        "    # The input elements\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            text = gr.Textbox(label=\"Text\", value=default_text)\n",
        "            # Precision=0 makes it an int, otherwise it's a float\n",
        "            # Value sets the initial default value\n",
        "            layer = gr.Number(label=\"Layer\", value=default_layer, precision=0)\n",
        "            neuron_index = gr.Number(\n",
        "                label=\"Neuron Index\", value=default_neuron_index, precision=0\n",
        "            )\n",
        "            # If empty, these two map to None\n",
        "            max_val = gr.Number(label=\"Max Value\", value=default_max_val)\n",
        "            min_val = gr.Number(label=\"Min Value\", value=default_min_val)\n",
        "            inputs = [text, layer, neuron_index, max_val, min_val]\n",
        "        with gr.Column():\n",
        "            # The output element\n",
        "            out = gr.HTML(label=\"Neuron Acts\", value=default_html_string)\n",
        "    for inp in inputs:\n",
        "        inp.change(basic_neuron_vis, inputs, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVOqJlhcPGMD"
      },
      "source": [
        "We can now launch our demo element, and we're done! The setting share=True even gives you a public link to the demo (though it just redirects to the backend run by this notebook, and will go away once you turn the notebook off!) Sharing makes it much slower, and can be turned off if you aren't in a colab.\n",
        "\n",
        "**Exercise:** Explore where this neuron does and does not activate. Is it just powers of ten? Just comma separated numbers? Numbers in any particular sequence?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OhjuVBj0PGME",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b904c0ca-ce20-46cc-fe6a-e0d836b75ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d4e085af-868f-4137.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d4e085af-868f-4137.gradio.live\" width=\"100%\" height=\"1000\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "demo.launch(share=True, height=1000)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}